{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4cf4fa9",
   "metadata": {},
   "source": [
    "# Control Phase — Monitoring & Drift Detection Simulation\n",
    "\n",
    "**Project:** Employee Attrition Prediction (DMAIC Framework)  \n",
    "**Notebook:** 06_control.ipynb  \n",
    "**Purpose:** Simulate production monitoring with statistical process control (SPC) tools\n",
    "\n",
    "This notebook demonstrates:\n",
    "- p-chart for prediction proportions\n",
    "- EWMA for metric trends\n",
    "- Page-Hinkley change detection\n",
    "- PSI (Population Stability Index) for feature drift\n",
    "- KL-divergence for categorical features\n",
    "- Optional ADWIN streaming drift detector\n",
    "\n",
    "**Note:** This simulates monitoring on historical data split into batches. In production, replace with live data streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77342767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Random seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 — Setup and imports\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "import os, json, time, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, \n",
    "    roc_auc_score, accuracy_score, confusion_matrix, \n",
    "    average_precision_score\n",
    ")\n",
    "from sklearn.utils import resample\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs('../figures', exist_ok=True)\n",
    "os.makedirs('../tables', exist_ok=True)\n",
    "os.makedirs('../reports', exist_ok=True)\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(f'Setup complete. Random seed: {RANDOM_SEED}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "176bc1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ../models/final_attrition_pipeline.pkl\n",
      "Data shape: (1470, 32)\n",
      "Attrition rate: 0.161\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — Load model and historical labeled data\n",
    "import joblib\n",
    "\n",
    "MODEL_PATH = '../models/final_attrition_pipeline.pkl'\n",
    "DATA_PATH = '../data/raw/WA_Fn-UseC_-HR-Employee-Attrition.csv'\n",
    "\n",
    "# Load final model\n",
    "pipeline = joblib.load(MODEL_PATH)\n",
    "print(f'Model loaded from {MODEL_PATH}')\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "target_col = 'Attrition'\n",
    "\n",
    "# Encode target if needed\n",
    "if df[target_col].dtype == object:\n",
    "    df[target_col] = df[target_col].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Remove constant columns (from EDA)\n",
    "constant_cols = ['EmployeeCount', 'Over18', 'StandardHours']\n",
    "df = df.drop(columns=[c for c in constant_cols if c in df.columns], errors='ignore')\n",
    "\n",
    "# Shuffle to simulate sequential batches\n",
    "df = df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "print(f'Data shape: {df.shape}')\n",
    "print(f'Attrition rate: {df[target_col].mean():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "466bbdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 30 batches\n",
      "Typical batch size: ~49 observations\n",
      "Batch size range: 49 to 49\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 — Create time-batches to simulate daily/weekly production\n",
    "n_batches = 30\n",
    "batch_size = int(np.ceil(len(df) / n_batches))\n",
    "batches = [df.iloc[i*batch_size:(i+1)*batch_size].copy() for i in range(n_batches)]\n",
    "\n",
    "print(f'Created {len(batches)} batches')\n",
    "print(f'Typical batch size: ~{batch_size} observations')\n",
    "print(f'Batch size range: {min(len(b) for b in batches)} to {max(len(b) for b in batches)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8905d68f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns are missing: {'EmployeeCount', 'StandardHours', 'Over18'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m yb = batch[target_col].values\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Generate predictions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m probs = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXb\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[32m1\u001b[39m]\n\u001b[32m     11\u001b[39m preds = (probs >= THRESHOLD).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Compute metrics\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\sixsigma-ml-attrition\\venv\\Lib\\site-packages\\sklearn\\pipeline.py:904\u001b[39m, in \u001b[36mPipeline.predict_proba\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m    902\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[32m    903\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter(with_final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m         Xt = \u001b[43mtransform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m1\u001b[39m].predict_proba(Xt, **params)\n\u001b[32m    907\u001b[39m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\sixsigma-ml-attrition\\venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\sixsigma-ml-attrition\\venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1085\u001b[39m, in \u001b[36mColumnTransformer.transform\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m   1083\u001b[39m     diff = all_names - \u001b[38;5;28mset\u001b[39m(column_names)\n\u001b[32m   1084\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[32m-> \u001b[39m\u001b[32m1085\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcolumns are missing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1086\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1087\u001b[39m     \u001b[38;5;66;03m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[32m   1088\u001b[39m     \u001b[38;5;66;03m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[32m   1089\u001b[39m     _check_n_features(\u001b[38;5;28mself\u001b[39m, X, reset=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mValueError\u001b[39m: columns are missing: {'EmployeeCount', 'StandardHours', 'Over18'}"
     ]
    }
   ],
   "source": [
    "# Cell 4 — Compute per-batch metrics\n",
    "THRESHOLD = 0.388  # Optimal threshold from 05_final_model.ipynb\n",
    "\n",
    "batch_metrics = []\n",
    "for i, batch in enumerate(batches):\n",
    "    Xb = batch.drop(columns=[target_col])\n",
    "    yb = batch[target_col].values\n",
    "    \n",
    "    # Generate predictions\n",
    "    probs = pipeline.predict_proba(Xb)[:, 1]\n",
    "    preds = (probs >= THRESHOLD).astype(int)\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics = {\n",
    "        'batch': i,\n",
    "        'n': len(batch),\n",
    "        'f1': f1_score(yb, preds, zero_division=0),\n",
    "        'precision': precision_score(yb, preds, zero_division=0),\n",
    "        'recall': recall_score(yb, preds, zero_division=0),\n",
    "        'accuracy': accuracy_score(yb, preds),\n",
    "        'roc_auc': roc_auc_score(yb, probs) if len(np.unique(yb)) > 1 else np.nan,\n",
    "        'pr_auc': average_precision_score(yb, probs) if len(np.unique(yb)) > 1 else np.nan,\n",
    "        'pos_rate': preds.mean(),\n",
    "        'prob_mean': probs.mean(),\n",
    "        'prob_std': probs.std()\n",
    "    }\n",
    "    batch_metrics.append(metrics)\n",
    "\n",
    "metrics_df = pd.DataFrame(batch_metrics)\n",
    "metrics_df.to_csv('../tables/control_batch_metrics.csv', index=False)\n",
    "\n",
    "print('Batch metrics computed and saved.')\n",
    "print('\\nSummary statistics:')\n",
    "print(metrics_df[['f1', 'recall', 'precision', 'roc_auc', 'pos_rate']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082140df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 — p-chart for positive prediction rate\n",
    "# Monitor proportion of positive predictions with 3-sigma control limits\n",
    "\n",
    "pbar = metrics_df['pos_rate'].mean()\n",
    "n = metrics_df['n'].mean()  # Average sample size\n",
    "z = 3  # 3-sigma control limits\n",
    "sigma = np.sqrt(pbar * (1 - pbar) / n)\n",
    "ucl = pbar + z * sigma\n",
    "lcl = max(0, pbar - z * sigma)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(metrics_df['batch'], metrics_df['pos_rate'], marker='o', \n",
    "         color='steelblue', label='Positive rate', markersize=6)\n",
    "plt.axhline(pbar, color='black', linestyle='--', linewidth=2, label=f'p̄ = {pbar:.3f}')\n",
    "plt.axhline(ucl, color='red', linestyle='--', linewidth=1.5, label=f'UCL = {ucl:.3f}')\n",
    "plt.axhline(lcl, color='red', linestyle='--', linewidth=1.5, label=f'LCL = {lcl:.3f}')\n",
    "plt.fill_between(metrics_df['batch'], lcl, ucl, color='red', alpha=0.05)\n",
    "\n",
    "plt.xlabel('Batch Number', fontsize=12)\n",
    "plt.ylabel('Proportion Positive Predictions', fontsize=12)\n",
    "plt.title('p-chart: Proportion of Positive Predictions by Batch (3σ limits)', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/pchart_pos_rate.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Check for violations\n",
    "p_violations = metrics_df[(metrics_df['pos_rate'] > ucl) | (metrics_df['pos_rate'] < lcl)]\n",
    "if len(p_violations) > 0:\n",
    "    print(f'⚠️ p-chart violations detected in {len(p_violations)} batches:')\n",
    "    print(p_violations[['batch', 'pos_rate']])\n",
    "else:\n",
    "    print('✓ No p-chart violations detected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f45abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 — EWMA chart for F1-score\n",
    "# Exponentially Weighted Moving Average to detect small sustained shifts\n",
    "\n",
    "lambda_ = 0.2  # EWMA smoothing parameter\n",
    "L = 3  # Control limit multiplier\n",
    "\n",
    "f1 = metrics_df['f1'].fillna(0).values\n",
    "z = np.zeros_like(f1)\n",
    "z[0] = f1[0]\n",
    "\n",
    "# Compute EWMA\n",
    "for t in range(1, len(f1)):\n",
    "    z[t] = lambda_ * f1[t] + (1 - lambda_) * z[t-1]\n",
    "\n",
    "# Compute control limits\n",
    "mu = np.mean(f1)\n",
    "sigma0 = np.std(f1, ddof=1)\n",
    "sigma_z = sigma0 * np.sqrt((lambda_ / (2 - lambda_)) * (1 - (1 - lambda_)**(2 * len(f1))))\n",
    "ucl_ewma = mu + L * sigma_z\n",
    "lcl_ewma = max(0, mu - L * sigma_z)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(metrics_df['batch'], f1, marker='o', color='lightblue', \n",
    "         alpha=0.5, label='Raw F1', markersize=4)\n",
    "plt.plot(metrics_df['batch'], z, marker='s', color='darkblue', \n",
    "         label=f'EWMA(F1) λ={lambda_}', linewidth=2, markersize=5)\n",
    "plt.axhline(mu, color='black', linestyle='--', linewidth=2, label=f'Mean F1 = {mu:.3f}')\n",
    "plt.axhline(ucl_ewma, color='red', linestyle='--', linewidth=1.5, label=f'EWMA UCL = {ucl_ewma:.3f}')\n",
    "plt.axhline(lcl_ewma, color='red', linestyle='--', linewidth=1.5, label=f'EWMA LCL = {lcl_ewma:.3f}')\n",
    "plt.fill_between(metrics_df['batch'], lcl_ewma, ucl_ewma, color='red', alpha=0.05)\n",
    "\n",
    "plt.xlabel('Batch Number', fontsize=12)\n",
    "plt.ylabel('F1-Score', fontsize=12)\n",
    "plt.title('EWMA Chart for F1-Score', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='best', fontsize=9)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/ewma_f1.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Check for violations\n",
    "ewma_violations = np.where((z > ucl_ewma) | (z < lcl_ewma))[0]\n",
    "if len(ewma_violations) > 0:\n",
    "    print(f'⚠️ EWMA violations detected in batches: {ewma_violations.tolist()}')\n",
    "else:\n",
    "    print('✓ No EWMA violations detected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3c5b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 — Page-Hinkley detector for mean predicted probability\n",
    "# Detects mean shifts in continuous metrics\n",
    "\n",
    "def page_hinkley(data, delta=0.005, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Page-Hinkley change detection algorithm.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: array of observations\n",
    "    - delta: drift threshold (small positive value)\n",
    "    - threshold: alarm threshold\n",
    "    \n",
    "    Returns:\n",
    "    - ph_stat: list of PH statistics\n",
    "    - alarm_indices: list of indices where alarm triggered\n",
    "    \"\"\"\n",
    "    m = 0.0\n",
    "    M = 1e9\n",
    "    ph_stat = []\n",
    "    alarm_indices = []\n",
    "    \n",
    "    for i, x in enumerate(data):\n",
    "        m += (x - m) / (i + 1)\n",
    "        diff = x - m - delta\n",
    "        M = min(M, diff)\n",
    "        ph = diff - M\n",
    "        ph_stat.append(ph)\n",
    "        \n",
    "        if ph > threshold:\n",
    "            alarm_indices.append(i)\n",
    "    \n",
    "    return ph_stat, alarm_indices\n",
    "\n",
    "prob_mean = metrics_df['prob_mean'].values\n",
    "ph_vals, ph_alarms = page_hinkley(prob_mean, delta=0.005, threshold=0.05)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(metrics_df['batch'], ph_vals, marker='o', color='purple', \n",
    "         label='Page-Hinkley statistic', markersize=6)\n",
    "plt.axhline(0.05, color='red', linestyle='--', linewidth=2, label='Alarm threshold = 0.05')\n",
    "\n",
    "# Mark alarm points\n",
    "if len(ph_alarms) > 0:\n",
    "    plt.scatter([metrics_df.loc[i, 'batch'] for i in ph_alarms], \n",
    "                [ph_vals[i] for i in ph_alarms],\n",
    "                color='red', s=100, marker='X', zorder=5, label='Alarms')\n",
    "\n",
    "plt.xlabel('Batch Number', fontsize=12)\n",
    "plt.ylabel('PH Statistic', fontsize=12)\n",
    "plt.title('Page-Hinkley Change Detection (Mean Predicted Probability)', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/page_hinkley.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "if len(ph_alarms) > 0:\n",
    "    print(f'⚠️ Page-Hinkley alarms detected in batches: {ph_alarms}')\n",
    "else:\n",
    "    print('✓ No Page-Hinkley alarms detected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec9c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 — PSI (Population Stability Index) per feature\n",
    "# Detects distribution shifts in numeric features\n",
    "\n",
    "def psi(expected, actual, bins=10):\n",
    "    \"\"\"\n",
    "    Calculate Population Stability Index.\n",
    "    \n",
    "    Parameters:\n",
    "    - expected: reference distribution (training data)\n",
    "    - actual: current distribution (batch data)\n",
    "    - bins: number of bins for discretization\n",
    "    \n",
    "    Returns:\n",
    "    - PSI value\n",
    "    \"\"\"\n",
    "    # Create bins from expected distribution\n",
    "    breakpoints = np.percentile(expected, np.linspace(0, 100, bins + 1))\n",
    "    breakpoints = np.unique(breakpoints)  # Remove duplicates\n",
    "    \n",
    "    # Compute distributions\n",
    "    expected_pct = np.histogram(expected, bins=breakpoints)[0] / len(expected)\n",
    "    actual_pct = np.histogram(actual, bins=breakpoints)[0] / len(actual)\n",
    "    \n",
    "    # Replace zeros to avoid division by zero\n",
    "    expected_pct = np.where(expected_pct == 0, 1e-6, expected_pct)\n",
    "    actual_pct = np.where(actual_pct == 0, 1e-6, actual_pct)\n",
    "    \n",
    "    # Calculate PSI\n",
    "    psi_val = np.sum((actual_pct - expected_pct) * np.log(actual_pct / expected_pct))\n",
    "    \n",
    "    return psi_val\n",
    "\n",
    "# Use first 3 batches as reference\n",
    "ref = pd.concat(batches[:3])\n",
    "print(f'Reference distribution: {len(ref)} observations from first 3 batches')\n",
    "\n",
    "# Get numeric features\n",
    "numeric_features = df.select_dtypes(include=[np.number]).columns.drop([target_col]).tolist()\n",
    "print(f'Monitoring {len(numeric_features)} numeric features for PSI')\n",
    "\n",
    "# Compute PSI for each batch\n",
    "psi_results = []\n",
    "for i, batch in enumerate(batches):\n",
    "    psi_batch = {'batch': i}\n",
    "    for feat in numeric_features:\n",
    "        psi_val = psi(ref[feat].values, batch[feat].values, bins=10)\n",
    "        psi_batch[feat] = psi_val\n",
    "    psi_results.append(psi_batch)\n",
    "\n",
    "psi_df = pd.DataFrame(psi_results)\n",
    "psi_df.to_csv('../tables/psi_by_batch.csv', index=False)\n",
    "\n",
    "print('\\nPSI computed for all batches.')\n",
    "print('\\nTop 10 features by mean PSI:')\n",
    "psi_means = psi_df.drop(columns='batch').mean().sort_values(ascending=False).head(10)\n",
    "print(psi_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8267c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9 — PSI heatmap visualization\n",
    "# Visualize PSI trends across batches and features\n",
    "\n",
    "# Select top features by mean PSI\n",
    "top_feats = psi_df.drop(columns='batch').mean().sort_values(ascending=False).head(15).index.tolist()\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(psi_df.set_index('batch')[top_feats].T, \n",
    "            cmap='YlOrRd', annot=False, cbar_kws={'label': 'PSI'},\n",
    "            vmin=0, vmax=0.25, linewidths=0.5)\n",
    "plt.xlabel('Batch Number', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('PSI Heatmap: Top 15 Features by Batch', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add threshold lines as text\n",
    "plt.text(1.02, 0.5, 'PSI < 0.1: Stable\\n0.1 ≤ PSI < 0.2: Moderate\\nPSI ≥ 0.2: High drift', \n",
    "         transform=plt.gca().transAxes, fontsize=9, verticalalignment='center',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/psi_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Check for high PSI violations\n",
    "high_psi = psi_df.set_index('batch').apply(lambda row: (row >= 0.2).sum(), axis=1)\n",
    "moderate_psi = psi_df.set_index('batch').apply(lambda row: ((row >= 0.1) & (row < 0.2)).sum(), axis=1)\n",
    "\n",
    "print(f'\\nBatches with high PSI (≥0.2) in any feature: {(high_psi > 0).sum()}')\n",
    "print(f'Batches with moderate PSI (0.1-0.2) in any feature: {(moderate_psi > 0).sum()}')\n",
    "\n",
    "if (high_psi > 0).any():\n",
    "    print('\\n⚠️ High PSI detected in batches:', high_psi[high_psi > 0].index.tolist())\n",
    "else:\n",
    "    print('\\n✓ No high PSI violations detected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db316c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10 — KL divergence for categorical features\n",
    "# Monitor distribution shifts in categorical variables\n",
    "\n",
    "# Get categorical features\n",
    "cat_features = [c for c in df.columns if df[c].dtype == 'object' and c != target_col]\n",
    "print(f'Monitoring {len(cat_features)} categorical features for KL divergence')\n",
    "\n",
    "kl_results = []\n",
    "for i, batch in enumerate(batches):\n",
    "    kl_row = {'batch': i}\n",
    "    for feat in cat_features:\n",
    "        # Get distributions\n",
    "        ref_dist = ref[feat].value_counts(normalize=True)\n",
    "        batch_dist = batch[feat].value_counts(normalize=True)\n",
    "        \n",
    "        # Align indices\n",
    "        all_idx = sorted(set(ref_dist.index).union(set(batch_dist.index)))\n",
    "        p = np.array([ref_dist.get(k, 1e-6) for k in all_idx])\n",
    "        q = np.array([batch_dist.get(k, 1e-6) for k in all_idx])\n",
    "        \n",
    "        # Compute KL divergence\n",
    "        kl = entropy(p, q)  # KL(P||Q)\n",
    "        kl_row[feat] = kl\n",
    "    kl_results.append(kl_row)\n",
    "\n",
    "kl_df = pd.DataFrame(kl_results)\n",
    "kl_df.to_csv('../tables/kl_by_batch.csv', index=False)\n",
    "\n",
    "print('\\nKL divergence computed for all batches.')\n",
    "print('\\nMean KL divergence by feature:')\n",
    "kl_summary = kl_df.drop(columns='batch').mean().sort_values(ascending=False)\n",
    "print(kl_summary)\n",
    "\n",
    "# Visualize KL trends\n",
    "if len(cat_features) > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for feat in cat_features:\n",
    "        plt.plot(kl_df['batch'], kl_df[feat], marker='o', label=feat, alpha=0.7)\n",
    "    \n",
    "    plt.axhline(0.1, color='orange', linestyle='--', linewidth=1.5, label='KL = 0.1 (moderate)')\n",
    "    plt.axhline(0.2, color='red', linestyle='--', linewidth=1.5, label='KL = 0.2 (high)')\n",
    "    \n",
    "    plt.xlabel('Batch Number', fontsize=12)\n",
    "    plt.ylabel('KL Divergence', fontsize=12)\n",
    "    plt.title('KL Divergence for Categorical Features', fontsize=14, fontweight='bold')\n",
    "    plt.legend(loc='best', fontsize=9)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../figures/kl_divergence.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Check for violations\n",
    "    high_kl = kl_df.set_index('batch').apply(lambda row: (row >= 0.2).sum(), axis=1)\n",
    "    if (high_kl > 0).any():\n",
    "        print('\\n⚠️ High KL divergence (≥0.2) detected in batches:', high_kl[high_kl > 0].index.tolist())\n",
    "    else:\n",
    "        print('\\n✓ No high KL divergence violations detected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a57cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11 — Optional ADWIN detector (requires river library)\n",
    "# Adaptive Windowing for streaming drift detection\n",
    "\n",
    "try:\n",
    "    from river.drift import ADWIN\n",
    "    \n",
    "    adwin = ADWIN()\n",
    "    adwin_alerts = []\n",
    "    \n",
    "    # Feed mean predicted probability stream\n",
    "    for i, val in enumerate(metrics_df['prob_mean'].values):\n",
    "        adwin.update(val)\n",
    "        if adwin.change_detected:\n",
    "            adwin_alerts.append(i)\n",
    "    \n",
    "    if len(adwin_alerts) > 0:\n",
    "        print(f'⚠️ ADWIN drift alarms detected in batches: {adwin_alerts}')\n",
    "        print('   These are high-priority alerts indicating distribution changes.')\n",
    "    else:\n",
    "        print('✓ No ADWIN drift alarms detected.')\n",
    "        \n",
    "except ImportError:\n",
    "    print('ℹ️ ADWIN detector not available.')\n",
    "    print('   Install river library with: pip install river')\n",
    "    adwin_alerts = []\n",
    "except Exception as e:\n",
    "    print(f'⚠️ ADWIN error: {e}')\n",
    "    adwin_alerts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bae0bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12 — Alert logic and summary report\n",
    "# Consolidate all monitoring alerts\n",
    "\n",
    "alerts = []\n",
    "\n",
    "# p-chart alerts\n",
    "p_alerts = metrics_df[(metrics_df['pos_rate'] > ucl) | (metrics_df['pos_rate'] < lcl)]['batch'].tolist()\n",
    "if p_alerts:\n",
    "    alerts.append({\n",
    "        'type': 'p_chart',\n",
    "        'severity': 'MEDIUM',\n",
    "        'batches': p_alerts,\n",
    "        'description': 'Positive prediction rate outside 3σ control limits'\n",
    "    })\n",
    "\n",
    "# EWMA alerts\n",
    "ewma_alerts_list = list(metrics_df['batch'][ewma_violations])\n",
    "if ewma_alerts_list:\n",
    "    alerts.append({\n",
    "        'type': 'ewma',\n",
    "        'severity': 'HIGH',\n",
    "        'batches': ewma_alerts_list,\n",
    "        'description': 'EWMA F1-score outside control limits (sustained drift)'\n",
    "    })\n",
    "\n",
    "# Page-Hinkley alerts\n",
    "if ph_alarms:\n",
    "    alerts.append({\n",
    "        'type': 'page_hinkley',\n",
    "        'severity': 'HIGH',\n",
    "        'batches': ph_alarms,\n",
    "        'description': 'Mean shift detected in predicted probabilities'\n",
    "    })\n",
    "\n",
    "# PSI alerts (high drift)\n",
    "psi_alarms = []\n",
    "for idx, row in psi_df.iterrows():\n",
    "    high_feats = row.drop('batch')[row.drop('batch') >= 0.2].index.tolist()\n",
    "    if len(high_feats) > 0:\n",
    "        psi_alarms.append({\n",
    "            'batch': int(row['batch']),\n",
    "            'features': high_feats,\n",
    "            'max_psi': row[high_feats].max()\n",
    "        })\n",
    "\n",
    "if psi_alarms:\n",
    "    alerts.append({\n",
    "        'type': 'psi',\n",
    "        'severity': 'HIGH',\n",
    "        'batches': [a['batch'] for a in psi_alarms],\n",
    "        'description': 'PSI ≥ 0.2 detected (high feature drift)',\n",
    "        'details': psi_alarms\n",
    "    })\n",
    "\n",
    "# KL divergence alerts (if applicable)\n",
    "if len(cat_features) > 0:\n",
    "    kl_alarms = []\n",
    "    for idx, row in kl_df.iterrows():\n",
    "        high_kl_feats = row.drop('batch')[row.drop('batch') >= 0.2].index.tolist()\n",
    "        if len(high_kl_feats) > 0:\n",
    "            kl_alarms.append({\n",
    "                'batch': int(row['batch']),\n",
    "                'features': high_kl_feats\n",
    "            })\n",
    "    \n",
    "    if kl_alarms:\n",
    "        alerts.append({\n",
    "            'type': 'kl_divergence',\n",
    "            'severity': 'MEDIUM',\n",
    "            'batches': [a['batch'] for a in kl_alarms],\n",
    "            'description': 'KL divergence ≥ 0.2 in categorical features'\n",
    "        })\n",
    "\n",
    "# ADWIN alerts\n",
    "if adwin_alerts:\n",
    "    alerts.append({\n",
    "        'type': 'adwin',\n",
    "        'severity': 'CRITICAL',\n",
    "        'batches': adwin_alerts,\n",
    "        'description': 'ADWIN streaming drift alarm (immediate investigation required)'\n",
    "    })\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('MONITORING ALERT SUMMARY')\n",
    "print('='*60)\n",
    "\n",
    "if len(alerts) == 0:\n",
    "    print('✓ No alerts detected. All monitoring metrics within acceptable bounds.')\n",
    "else:\n",
    "    print(f'⚠️ Total alerts: {len(alerts)}\\n')\n",
    "    for i, alert in enumerate(alerts, 1):\n",
    "        print(f'{i}. [{alert[\"severity\"]}] {alert[\"type\"].upper()}')\n",
    "        print(f'   Description: {alert[\"description\"]}')\n",
    "        print(f'   Affected batches: {alert[\"batches\"]}')\n",
    "        if 'details' in alert:\n",
    "            print(f'   Details: {alert[\"details\"]}')\n",
    "        print()\n",
    "\n",
    "# Export report\n",
    "report = {\n",
    "    'monitoring_date': '2025-10-02',\n",
    "    'n_batches': len(batches),\n",
    "    'total_observations': len(df),\n",
    "    'metrics_summary': metrics_df[['f1', 'recall', 'precision', 'roc_auc', 'pos_rate']].describe().to_dict(),\n",
    "    'alerts': alerts,\n",
    "    'psi_summary': psi_df.drop(columns='batch').mean().sort_values(ascending=False).head(10).to_dict(),\n",
    "    'kl_summary': kl_df.drop(columns='batch').mean().to_dict() if len(cat_features) > 0 else {}\n",
    "}\n",
    "\n",
    "with open('../reports/control_report.json', 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print('\\n✓ Control report saved to: reports/control_report.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b74bd4",
   "metadata": {},
   "source": [
    "## Summary & Next Steps\n",
    "\n",
    "### Deliverables\n",
    "- **Figures:** p-chart, EWMA, Page-Hinkley, PSI heatmap, KL divergence plots saved to `figures/`\n",
    "- **Tables:** Batch metrics, PSI, KL divergence saved to `tables/`\n",
    "- **Report:** JSON alert summary saved to `reports/control_report.json`\n",
    "\n",
    "### Operational Recommendations\n",
    "1. **Tune parameters** on historical data:\n",
    "   - EWMA λ (currently 0.2)\n",
    "   - Page-Hinkley delta and threshold (currently 0.005 and 0.05)\n",
    "   - PSI bins and thresholds\n",
    "\n",
    "2. **Integrate with production monitoring stack:**\n",
    "   - Wire metrics to Prometheus/Grafana dashboards\n",
    "   - Configure PagerDuty/Slack alerts for CRITICAL/HIGH severity\n",
    "   - Use Evidently for automated drift reports\n",
    "\n",
    "3. **Establish retraining triggers:**\n",
    "   - Performance drop: F1 below LCL for 3 consecutive weeks\n",
    "   - Drift evidence: PSI ≥ 0.2 on any feature OR PSI ≥ 0.1 on >3 features\n",
    "   - Data volume: ≥500 new labeled observations\n",
    "   - Quarterly schedule (if no triggers)\n",
    "\n",
    "4. **Assign ownership:**\n",
    "   - Model Owner (Data Scientist): threshold tuning, triage, retraining\n",
    "   - Data Owner (HR/Domain): verify data changes, business context\n",
    "   - MLOps Lead: deployment, rollback, logging\n",
    "\n",
    "5. **Test rollback procedures:**\n",
    "   - Maintain last 3 model versions\n",
    "   - Document blue/green deployment process\n",
    "   - Practice incident response drills\n",
    "\n",
    "### Reference Documents\n",
    "- Full control plan: `paper/appendix_control_plan.md`\n",
    "- Model metadata: `models/model_metadata.json`\n",
    "- Final model: `models/final_attrition_pipeline.pkl`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
